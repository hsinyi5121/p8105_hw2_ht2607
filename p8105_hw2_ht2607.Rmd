---
title: "p8105_hw2_ht2607"
output: github_document
---

## Question 1

```{r setup, include=FALSE}
library(tidyverse)
library(tidyr)
```

```{r}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 

snp = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month) |>
  mutate(month = month.name[month]) |>
  select(year, month, close) 

unemployment = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)

data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

## Question 2

Step 1: Read, import, and clean Mr.Trash Wheel dataset. I also specify the sheet in the Excel file and omit non-data entries including the rows with notes/ figures, clumns containing notes using argument in read_excel. In addition, I omitted rows that do not include the dumpster-specific data. I also updated the data to every row by creating a column called homes_powered and applying the note to the created column based on the Homes powered note sheet, which home powered = weight tons*500/ 30. 

```{r}
library(readxl)
library(tidyverse)
mr_trash_df = read_excel("q2data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered = weight_tons*500/30)
```

Step 2: I used similar process in step 1 to import, clean, and organize the data for Professor Trash Wheel. Additionally, I updated the data to every row by creating a column called homes_powered and applying the note to the created column based on the Homes powered note sheet, which home powered = weight tons*500/ 30.

```{r}
professor_trash_df = read_excel("q2data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered = weight_tons*500/30)
```

Step 3: I used similar process in step 1 to import, clean, and organize the data for Gwynnda. Additionally, I updated the data to every row by creating a column called homes_powered and applying the note to the created column based on the Homes powered note sheet, which home powered = weight tons*500/ 30.

```{r}
gwynnda_df= read_excel("q2data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered = weight_tons*500/30)
```

Step 4: In order to combine the all the datasets together, I created a common variable called trash_wheel and labeled it as mr.trash in the mr_trash data frame. As I applied the procedure, the number of observations in mr_trash_df decrease from 584 to 107. 

```{r}
mr_trash_df = 
  readxl::read_excel("q2data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel") |>
  mutate(trash_wheel = "mr.trash")
```

Step 5: I also created a common variable called trash_wheel and labeled it as professor trash in the professor_trash data frame. Similiarly, as I applied the procedure, the number of observations in professor_trash_df increase from 106 to 107. 

```{r}
professor_trash_df = 
  readxl::read_excel("q2data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel") |>
  mutate(trash_wheel = "professor trash")
```

Step 6: Then, I created a common variable called trash_wheel and labeled it as gwynnda in the gwynnda data frame. I also applied the silimar procedure as I did for mr_trash and professor_trash data frame, and the number of observations in professor_trash_df increase from 155 to 157

```{r}
gwynnda_df = 
  readxl::read_excel("q2data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel") |>
  mutate(trash_wheel = "gwynnda")
```

Step 7: Since all the datasets (mr_trash, professor_trash, and gwynnda) have a common variable, then I combine them together by using bind_rows function and called it trash_df_tidy. In addition, I used janitor::clean_names function to clean the new dataframe that I just mergered.Therefore, in the trash_df_tidy comprises data from all trash collecting entities (Mr.Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel). The total observation in this data frame is 371, representing the trash collection events from different locations.
Some key variables from this dataset including weight_tons (the weight of trash collected during each event), homes_powered (the approximate number of home powered generated by the collected trash)

```{r}
trash_df_tidy = 
  bind_rows(mr_trash_df, professor_trash_df, gwynnda_df) |>
  janitor::clean_names()
```

Step 8: I calculated the total weight of trash collected by professor Trash Wheel. 

```{r}
sum(trash_df_tidy[trash_df_tidy$trash_wheel == "professor trash",]$weight_tons)
```

The total weight of trash collected by Professor Trash Wheel is  432.52.

The below code show how I calculated the total number of cigarette butts collected by Gwynnda in July of 2021. 

```{r}
sum(trash_df_tidy[trash_df_tidy$trash_wheel == "gwynnda" & trash_df_tidy$year== 2021 & trash_df_tidy$month== "July",]$cigarette_butts, na.rm = T)
```

The total number of cigarette butts collected by Gwynnda in July of 2021 is 16300.

## Question 3

Step 1: I imported and cleaned the MCI. During the process, I ensured that sex and APOE4 carrier status are appropriate encoded (not numeric). I also encoded the age at onset to be numeric.

```{r}
mci_df = read_csv(file = "./data_mci/MCI_baseline.csv", skip = 1, na = ".") |>
  janitor::clean_names() |> 
  drop_na() |> 
  mutate(
   sex = 
      case_match(
        sex, 
        1 ~ "male", 
        0 ~ "female"),
   sex = as.factor(sex)) |> 
  mutate(apoe4 = factor(apoe4, labels = c("APOE4 non-carrier", "APOE4 carrier")),
         age_at_onset = as.numeric (age_at_onset)) |> 
  drop_na(age_at_onset)
```

The below code show that there is 97 participants there were recruited in the dataset. 
```{r}
nrow(mci_df)
```

Among those particpants, there are 97 that developed MCI.
```{r}
sum(!is.na(mci_df$age_at_onset))
```

The average age for those who develop MCI is 65.61.
```{r}
mean(mci_df$current_age, na.rm=TRUE)
```

Step 2: I also imported and cleaned the amyloid file. To ensure that there will be no na in the dataset (variable in baseline, time_2, time_4, time_6, and time_8), I use drop_na function. Also, because we need to combine the mci_df with amyloid_df together for the further analysis process, so I created a new varibale called study_id and encoded to be numeric. Then I renamed the variable to called id so there will be a common variable in both data frame. 

```{r}
amyloid_df = read_csv(file = "./data_mci/mci_amyloid.csv", skip = 1, na = "NA") |>
  janitor::clean_names() |> 
  drop_na(baseline, time_2, time_4, time_6, time_8) |> 
mutate(
   study_id = as.numeric(study_id)) |> 
  rename(id = study_id)
```

Step 3: Similarly, in order to tidy the dataset of longitudinally observed biomarker values, I use pivot_longer function and created two columns called time and bipmarker from the orginal variable (baseline, time_2, time_4, time_6, and time_8). The new created dataset called amyloid_df_tidy. 

```{r}
amyloid_df_tidy = 
pivot_longer(
  amyloid_df,
    cols=c(baseline, time_2, time_4, time_6, time_8), 
    names_to = "time",
    values_to = "biomarker")
```

Step 4: Afterward, I combined the mci_df (demographic) and amyloid_df_tidy (biomarker) so that only particpants who appear in both datasets are retained. In addition, I remove any particpants who do no meet the stated inclusion criteria (such as no MCI at baseline).

```{r}
mci_df_tidy = 
 inner_join(mci_df, amyloid_df_tidy , by = "id") |> 
  janitor::clean_names() |> 
  filter(age_at_onset > current_age | is.na(age_at_onset))
```

The below code represent that there are total 315 participant that were recruited after combine the dataset. 
```{r}
nrow(mci_df_tidy)
```

Among them 315 of the particpants developed MCI.
```{r}
sum(!is.na(mci_df_tidy$age_at_onset))
```

The average baseline age is at 65.69.
```{r}
mean(mci_df_tidy$current_age)
```

The proportion of women in the study are APOE4 carriers is 0.65625.
```{r}
women_apoe_df= filter(mci_df_tidy, sex == "female")
table(women_apoe_df$apoe4)/ nrow(women_apoe_df)
```

Step 5: Exporting the file as a CSV to my data directory

```{r}
write.csv(mci_df_tidy, "C:\\Users\\Cindy\\Desktop\\p8105_hw2_ht2607\\hw2.csv", row.names=FALSE)
```

