p8105_hw2_ht2607
================

## Question 1

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_num)`

``` r
snp = 
  read_csv("fivethirtyeight_datasets/snp.csv") |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month) |>
  mutate(month = month.name[month]) |>
  select(year, month, close) 
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
unemployment = 
  read_csv("fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_abb)`

``` r
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

``` r
str(data_538)
```

    ## tibble [822 × 13] (S3: tbl_df/tbl/data.frame)
    ##  $ year        : num [1:822] 1947 1947 1947 1947 1947 ...
    ##  $ month       : chr [1:822] "January" "February" "March" "April" ...
    ##  $ month_num   : int [1:822] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ gov_gop     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_gop     : num [1:822] 51 51 51 51 51 51 51 51 51 51 ...
    ##  $ rep_gop     : num [1:822] 253 253 253 253 253 253 253 253 253 253 ...
    ##  $ gov_dem     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_dem     : num [1:822] 45 45 45 45 45 45 45 45 45 45 ...
    ##  $ rep_dem     : num [1:822] 198 198 198 198 198 198 198 198 198 198 ...
    ##  $ president   : chr [1:822] "dem" "dem" "dem" "dem" ...
    ##  $ month_abb   : chr [1:822] "Jan" "Feb" "Mar" "Apr" ...
    ##  $ close       : num [1:822] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ unemployment: num [1:822] NA NA NA NA NA NA NA NA NA NA ...

## Question 2

Step 1: Read, import, and clean Mr.Trash Wheel dataset. I also specify
the sheet in the Excel file and omit non-data entries including the rows
with notes/ figures, clumns containing notes using argument in
read_excel. In addition, I omitted rows that do not include the
dumpster-specific data. I also updated the data to every row by creating
a column called homes_powered and applying the note to the created
column based on the Homes powered note sheet, which home powered =
weight tons\*500/ 30.

``` r
library(readxl)
library(tidyverse)
mr_trash_df = read_excel("q2data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered = weight_tons*500/30)
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

Step 2: I used similar process in step 1 to import, clean, and organize
the data for Professor Trash Wheel. Additionally, I updated the data to
every row by creating a column called homes_powered and applying the
note to the created column based on the Homes powered note sheet, which
home powered = weight tons\*500/ 30.

``` r
professor_trash_df = read_excel("q2data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered = weight_tons*500/30)
```

Step 3: I used similar process in step 1 to import, clean, and organize
the data for Gwynnda. Additionally, I updated the data to every row by
creating a column called homes_powered and applying the note to the
created column based on the Homes powered note sheet, which home powered
= weight tons\*500/ 30.

``` r
gwynnda_df= read_excel("q2data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(homes_powered = weight_tons*500/30)
```

Step 4: In order to combine the all the datasets together, I created a
common variable called trash_wheel and labeled it as mr.trash in the
mr_trash data frame. As I applied the procedure, the number of
observations in mr_trash_df decrease from 584 to 107.

``` r
mr_trash_df = 
  readxl::read_excel("q2data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel") |>
  mutate(trash_wheel = "mr.trash")
```

Step 5: I also created a common variable called trash_wheel and labeled
it as professor trash in the professor_trash data frame. Similiarly, as
I applied the procedure, the number of observations in
professor_trash_df increase from 106 to 107.

``` r
professor_trash_df = 
  readxl::read_excel("q2data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel") |>
  mutate(trash_wheel = "professor trash")
```

Step 6: Then, I created a common variable called trash_wheel and labeled
it as gwynnda in the gwynnda data frame. I also applied the silimar
procedure as I did for mr_trash and professor_trash data frame, and the
number of observations in professor_trash_df increase from 155 to 157

``` r
gwynnda_df = 
  readxl::read_excel("q2data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel") |>
  mutate(trash_wheel = "gwynnda")
```

Step 7: Since all the datasets (mr_trash, professor_trash, and gwynnda)
have a common variable, then I combine them together by using bind_rows
function and called it trash_df_tidy. In addition, I used
janitor::clean_names function to clean the new dataframe that I just
mergered.Therefore, in the trash_df_tidy comprises data from all trash
collecting entities (Mr.Trash Wheel, Professor Trash Wheel, and Gwynnda
Trash Wheel). The total observation in this data frame is 371,
representing the trash collection events from different locations. Some
key variables from this dataset including weight_tons (the weight of
trash collected during each event), homes_powered (the approximate
number of home powered generated by the collected trash)

``` r
trash_df_tidy = 
  bind_rows(mr_trash_df, professor_trash_df, gwynnda_df) |>
  janitor::clean_names()
```

Step 8: I calculated the total weight of trash collected by professor
Trash Wheel.

``` r
sum(trash_df_tidy[trash_df_tidy$trash_wheel == "professor trash",]$weight_tons)
```

    ## [1] 432.52

The total weight of trash collected by Professor Trash Wheel is 432.52.

The below code show how I calculated the total number of cigarette butts
collected by Gwynnda in July of 2021.

``` r
sum(trash_df_tidy[trash_df_tidy$trash_wheel == "gwynnda" & trash_df_tidy$year== 2021 & trash_df_tidy$month== "July",]$cigarette_butts, na.rm = T)
```

    ## [1] 16300

The total number of cigarette butts collected by Gwynnda in July of 2021
is 16300.

## Question 3

Step 1: I imported and cleaned the MCI. During the process, I ensured
that sex and APOE4 carrier status are appropriate encoded (not numeric).
I also encoded the age at onset to be numeric.

``` r
mci_df = read_csv(file = "./data_mci/MCI_baseline.csv", skip = 1, na = ".") |>
  janitor::clean_names() |> 
  drop_na() |> 
  mutate(
   sex = 
      case_match(
        sex, 
        1 ~ "male", 
        0 ~ "female"),
   sex = as.factor(sex)) |> 
  mutate(apoe4 = factor(apoe4, labels = c("APOE4 non-carrier", "APOE4 carrier")),
         age_at_onset = as.numeric (age_at_onset)) |> 
  drop_na(age_at_onset)
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (6): ID, Current Age, Sex, Education, apoe4, Age at onset
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

The below code show that there is 97 participants there were recruited
in the dataset.

``` r
nrow(mci_df)
```

    ## [1] 97

Among those particpants, there are 97 that developed MCI.

``` r
sum(!is.na(mci_df$age_at_onset))
```

    ## [1] 97

The average age for those who develop MCI is 65.61.

``` r
mean(mci_df$current_age, na.rm=TRUE)
```

    ## [1] 65.61134

Step 2: I also imported and cleaned the amyloid file. To ensure that
there will be no na in the dataset (variable in baseline, time_2,
time_4, time_6, and time_8), I use drop_na function. Also, because we
need to combine the mci_df with amyloid_df together for the further
analysis process, so I created a new varibale called study_id and
encoded to be numeric. Then I renamed the variable to called id so there
will be a common variable in both data frame.

``` r
amyloid_df = read_csv(file = "./data_mci/mci_amyloid.csv", skip = 1, na = "NA") |>
  janitor::clean_names() |> 
  drop_na(baseline, time_2, time_4, time_6, time_8) |> 
mutate(
   study_id = as.numeric(study_id)) |> 
  rename(id = study_id)
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Step 3: Similarly, in order to tidy the dataset of longitudinally
observed biomarker values, I use pivot_longer function and created two
columns called time and bipmarker from the orginal variable (baseline,
time_2, time_4, time_6, and time_8). The new created dataset called
amyloid_df_tidy.

``` r
amyloid_df_tidy = 
pivot_longer(
  amyloid_df,
    cols=c(baseline, time_2, time_4, time_6, time_8), 
    names_to = "time",
    values_to = "biomarker")
```

Step 4: Afterward, I combined the mci_df (demographic) and
amyloid_df_tidy (biomarker) so that only particpants who appear in both
datasets are retained. In addition, I remove any particpants who do no
meet the stated inclusion criteria (such as no MCI at baseline).

``` r
mci_df_tidy = 
 inner_join(mci_df, amyloid_df_tidy , by = "id") |> 
  janitor::clean_names() |> 
  filter(age_at_onset > current_age | is.na(age_at_onset))
```

The below code represent that there are total 315 participant that were
recruited after combine the dataset.

``` r
nrow(mci_df_tidy)
```

    ## [1] 315

Among them 315 of the particpants developed MCI.

``` r
sum(!is.na(mci_df_tidy$age_at_onset))
```

    ## [1] 315

The average baseline age is at 65.69.

``` r
mean(mci_df_tidy$current_age)
```

    ## [1] 65.69683

The proportion of women in the study are APOE4 carriers is 0.65625.

``` r
women_apoe_df= filter(mci_df_tidy, sex == "female")
table(women_apoe_df$apoe4)/ nrow(women_apoe_df)
```

    ## 
    ## APOE4 non-carrier     APOE4 carrier 
    ##           0.34375           0.65625

Step 5: Exporting the file as a CSV to my data directory

``` r
write.csv(mci_df_tidy, "C:\\Users\\Cindy\\Desktop\\p8105_hw2_ht2607\\hw2.csv", row.names=FALSE)
```
